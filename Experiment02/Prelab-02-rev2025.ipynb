{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f23c3085-0598-4242-8f0b-d1aa3969b83f",
   "metadata": {},
   "source": [
    "# Prelab Experiment 02"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87a1ae6-0a37-44a0-b300-5d1c8469867d",
   "metadata": {},
   "source": [
    "This notebook help you gain more familiarity with doing some calculations and performing fits in Python while also reviewing some concepts for the upcoming experiment with RC circuit transient signals. Parts of this notebook pair with the Canvas quiz. You will also need to upload the notebook saved as a .html file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11473a25-239e-48d5-818e-320708fe900c",
   "metadata": {},
   "source": [
    "## Calculate an RC time constant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544d8c7d-57bc-4540-b78e-fc6200c47111",
   "metadata": {},
   "source": [
    "Using the component values given in your Canvas quiz, calculate the expected decay constant, $\\tau$ for an RC circuit. You will need to write the expressions in the code block below for both the RC time constant, and it's uncertainty. \n",
    "\n",
    "Some basic math functions in python you might need or encounter:\n",
    "* multiplication is done with an asterisk ``*``\n",
    "* division is done with the slash ``/``\n",
    "* addition and subtraction are ``+`` and ``-``\n",
    "* exponentiation is done with a double asterisk ``**`` (e.g. $3^2$ is coded as ``3**2``)\n",
    "* a square root function exists within the ``numpy`` package as ``np.sqrt()``\n",
    "* an absolute value exists within the ``numpy`` package as ``np.abs``\n",
    "\n",
    "More ``numpy`` functions can be found on the Numpy cheat sheet on canvas. Although you won't need it this week, many of these functions also work with arrays as well as scalars.\n",
    "\n",
    "You can add your code to do your RC time constant and uncertainty calculation in the cell below or in an additional code cell (or more). Just make sure you run the line to import numpy as np before using the numpy functions.\n",
    "\n",
    "Being able to do quick calculations within your Jupyter notebook will be very handy in the lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9d15ce-450a-4015-8613-475be21d2d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7069b8cb-1223-494e-ac11-3b97bcccb64e",
   "metadata": {},
   "source": [
    "Make sure to report the result with an apporpriate number of significant figures based on the uncertainty. You can either do this by transcribing the result into a markdown cell, or by using a format statement when you print the result."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683e6b06-e6b8-41fa-99f8-2fb2c56c9290",
   "metadata": {},
   "source": [
    "### Formatting numerical output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20781f0-a1ed-4cbb-8beb-d15b8ed99018",
   "metadata": {},
   "source": [
    "The numbers we work with most of the time are called \"floats\" or floating-point numbers; these are a way of storing values with decimals that consists of an integer (the significand) and an exponent to place the decimal correctly. The computer stores as many places as it can for the number type (floats in Python are 64-bit double-precision values), but when they are printed they are technically converted to a string first. So, we can specify how we want that string printed.\n",
    "\n",
    "When we input a `print` command we can add a format string to tell python what to give back so that it looks like `print(f\"{mybignumber:specifier}\")`. Different format strings do different things:\n",
    "* if we just care about the number of places after the decimal we can use a `.nf` specifier where n is the number of places after the decimal\n",
    "* if we just care about the number of significant digits (counting before and after the decimal) use `.ng` where n is the nubmer of significant digits (for example, we always want uncertainty to 1 sig fig!)\n",
    "* if we want to specify both the leading and trailing digits we can specify a fixed-width with `m.nf` where m is the nubmer of spaces/digits including the decimal, and n specifies the precision as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4e7a4f9c-27f9-459a-867e-77360a2d1e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.8870000000000005\n",
      "6.8870\n",
      "7\n",
      "  289\n"
     ]
    }
   ],
   "source": [
    "x=289.254\n",
    "y=42\n",
    "z=x/y\n",
    "\n",
    "print(z) # full float\n",
    "print(f\"{z:.4f}\") # 4 decimal places\n",
    "print(f\"{z:.1g}\") # 1 significant digit\n",
    "print(f\"{x:5.0f}\") # 5 places total (including the decimal) and 0 places after"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a91ca49c-450c-4685-8db7-57707329fd91",
   "metadata": {},
   "source": [
    "## Pack and trim the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed81a75-ed0a-4332-9f8f-b3b652e09f42",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "Last week you used a code block to reduce the number of data points as well as estimate the uncertainties. You will use the same routine again, but now because you are only interested in fitting an exponential decay (not a series of charging and discharge cycles) you will need to isolate the region of interest. We will do this by \"trimming\" the data down to just the part we are interested in.\n",
    "\n",
    "You will need to load in the sample data and determine what region you want to use for fitting an exponential decay model (below)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c849ce18-24ae-4e04-8f75-7cdadc623a38",
   "metadata": {},
   "source": [
    "Below, we have provided a more compact version of the code you used last week to examine your data and then do some averaging to pack it. Once you have saved a set of data from the oscilloscope, and uploaded it to your Jupyter account, the entire code runs in one cell. You will probably need to run it several times until you are satisfied with the final output. The key pieces of code that you will need to alter include:\n",
    "- the name for your uploaded raw data file `fname`\n",
    "- the zoomed in flat range you use to examine the noise and measure the standard deviation `indexraw_min` to `indexraw_max`\n",
    "- the corresponding y-range for the selected region to examine `yregion_min` to `yregion_max`\n",
    "- the number of points you want to average when packing the data `npac`\n",
    "- to trim unwanted data set the flag `trim` to `1`, and enter `trim_min` and `trim_max` limits of the PACKED indices to include this data only; note if `trim` is set to `0` the full data set will be packed and saved\n",
    "- the filename you will use to save your packed and trimmed data `output_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061215a-e2bb-41eb-9a48-465a2768e07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the  necessary libraries and rename them\n",
    "import numpy as np\n",
    "import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###############################################################################\n",
    "# LIST OF ALL INPUTS\n",
    "###############################################################################\n",
    "\n",
    "fname = 'something.csv' # file name containing your raw data\n",
    "\n",
    "# choose the data range you want to examine\n",
    "indexraw_min = 0\n",
    "indexraw_max = 2000\n",
    "\n",
    "# set y-scale to correspond to this range\n",
    "yregion_min=5.2\n",
    "yregion_max=4.8\n",
    "\n",
    "npac=100 # define packing factor  npac\n",
    "\n",
    "# trim data set range before output to .csv file\n",
    "trim = 0 # default is 0 to save full dataset, set trim to 1 to trim the output data then give the range\n",
    "trim_min=50 # start of trimmed data by packed index\n",
    "trim_max=800 # end of trimmed data by packed index\n",
    "\n",
    "title='My Packed MicSig Data' # give your graph a title\n",
    "output_name = 'something_packed.csv' # provide an output filename for the packed data\n",
    "\n",
    "\n",
    "# read in data - the file is assumed to be in csv format (comma separated variables). \n",
    "#Files need to be specified with a full path OR they have to be saved in the same folder \n",
    "#as the script\n",
    "data = np.loadtxt(fname, delimiter=',', comments='#',usecols=(3,4),skiprows=1)\n",
    "#data = np.loadtxt(fname, delimiter=',',comments='#' )\n",
    "# access the data columns and assign variables xraw and yraw\n",
    "#generate  an array  xraw  which is the first  column  of  data.  Note the first column is \n",
    "#indexed as  zero.\n",
    "xraw = data[:,0]\n",
    "#generate  an array  yraw  which is the second  column  of  data  (index  1)\n",
    "yraw = data[:,1]\n",
    "#generate array containing index\n",
    "indexraw=np.arange(len(xraw))\n",
    "\n",
    "# plot data versus time and data versus index\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.scatter(xraw, yraw,marker='.')\n",
    "ax1.set_xlabel('Time (sec)')\n",
    "ax1.set_ylabel('Voltage (V)')\n",
    "ax1.set_title('My Raw MicSig Data')\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.scatter(indexraw,yraw,marker='.')\n",
    "ax2.set_xlabel('Index')\n",
    "ax2.set_ylabel('Voltage (V)')\n",
    "plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# PLOT RESTRICTED INDEX RANGE OF FLAT DATA, CALCULATE UNCERTAINTY\n",
    "# plots a restricted index range where the data is flat\n",
    "# and calculates the standard deviation to assess the noise\n",
    "###############################################################################\n",
    "\n",
    "# change axis limits\n",
    "plt.xlim(indexraw_min,indexraw_max)\n",
    "plt.ylim(yregion_min,yregion_max)\n",
    "\n",
    "# plot the data versus index\n",
    "plt.scatter(indexraw,yraw,marker='.')\n",
    "\n",
    "# This next command displays the index plot. \n",
    "plt.show()\n",
    "\n",
    "#calculate and display the mean and standard deviation of the data that you have zoomed in on.\n",
    "y_ave = np.mean(yraw[indexraw_min:indexraw_max])\n",
    "y_std = np.std(yraw[indexraw_min:indexraw_max])\n",
    "print('mean = ',y_ave)\n",
    "print('standard deviation = ', y_std)\n",
    "\n",
    "# display a histogram of the data\n",
    "hist,bins = np.histogram(yraw[indexraw_min:indexraw_max],bins=20)\n",
    "plt.bar(bins[:-1],hist,width=bins[1]-bins[0])\n",
    "plt.ylim(0,1.2*np.max(hist))\n",
    "plt.xlabel('y_raw (Volts)')\n",
    "plt.ylabel('Number of occurences')\n",
    "plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# PACK AND TRIM DATA\n",
    "###############################################################################\n",
    "\n",
    "#define a function  to pack the data\n",
    "def pack(A,p):\n",
    "  # A is an array, and p is the packing factor\n",
    "  B = np.zeros(len(A)//p)\n",
    "  i = 1\n",
    "  while i-1<len(B):\n",
    "    B[i-1] = np.mean(A[p*(i-1):p*i])\n",
    "    i += 1\n",
    "  return B\n",
    "# pack the data\n",
    "x=pack(xraw,npac)\n",
    "y=pack(yraw,npac)\n",
    "\n",
    "#create a vector that also has the integer index (index = 0,1,2 ... length-1)\n",
    "length=len(x)\n",
    "#print(length)\n",
    "index = np.arange(length)\n",
    "\n",
    "#create a vector that contains fixed uncertainty for x values (in this case set to zero\n",
    "sigmax = [0]*length\n",
    "#print(sigmax)\n",
    "\n",
    "#Create a vector that contains uncertainty of averaged y values. \n",
    "#sigmayraw is your estimate of the uncertainty in individual raw data points\n",
    "\n",
    "#Here it is taking that value from your previous statistics code \n",
    "#If you think the standard deviation of your data is an underestimate of the uncertainty,\n",
    "#you can also enter a value by hand - just change the line that defines simayraw\n",
    "sigmayraw = y_std\n",
    "\n",
    "#sigmaymean is the uncertainty of y after averaging npac points together\n",
    "#sigmay is an array of uncertainties, all of the same value as sigmaymean\n",
    "sigmaymean = sigmayraw/np.sqrt(npac)\n",
    "sigmay = [sigmaymean]*length\n",
    "\n",
    "print('packing is done by averaging', npac, 'data points')\n",
    "\n",
    "if trim == 1:\n",
    "    index_min=trim_min\n",
    "    index_max=trim_max\n",
    "    print('packed data has been trimmed from ', index_min, 'to ', index_max)\n",
    "else:\n",
    "    index_min=0\n",
    "    index_max=length\n",
    "    print('packed data contains full data set')\n",
    "\n",
    "# plot the trimmed data versus index\n",
    "plt.errorbar(index,y,yerr=sigmay,marker='.',linestyle='')\n",
    "## marker='o' : use markers to indicate each data point (x_1,y_1),(x_2,y_2)\n",
    "## linestyle= '' : no line is drawn to connect the data points\n",
    "## linestyle= '-' : a line is drawn to connect the data points\n",
    "\n",
    "# change axis limits\n",
    "plt.xlim(index_min,index_max)\n",
    "\n",
    "# add axis labels\n",
    "plt.title('Packed and Trimmed Data For Storage')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.show()\n",
    "\n",
    "# Create Array and output as CSV file in four-column format with two-row headers\n",
    "\n",
    "header = [np.array(['time','u[time]','Voltage','u[Voltage]']), \n",
    "np.array(['(sec)','(sec)','(V)','(V)'])]\n",
    "d1 = [x[index_min:index_max] , sigmax[index_min:index_max] , y[index_min:index_max] , sigmay[index_min:index_max]]\n",
    "d1_a = np.array(d1)\n",
    "df = pd.DataFrame(np.transpose(d1_a), columns=header )   \n",
    "    \n",
    "# print(df)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# SAVE DATA TO FILE\n",
    "###############################################################################\n",
    "\n",
    "csv_data = df.to_csv(output_name, index = False)\n",
    "print('Packed Data Stored in ', output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116b1245-5a3c-4faf-8654-aad791d4436b",
   "metadata": {},
   "source": [
    "## Fit an exponential to sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93acf466-25fa-41a6-b428-f4400e06e2df",
   "metadata": {},
   "source": [
    "Instructions:\n",
    "\n",
    "Using the standardized code block for fitting included below, change the fit function to an exponential and adjust the initial guesses (hint: you have calculated an RC time constant above with values consistent with the ones used for this data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5bd5122-6db6-4b02-91f2-0fea0a3e0f9b",
   "metadata": {},
   "source": [
    "Fitting:\n",
    "\n",
    "The following code block is identical to the Fitting-general-2024-v0.2 notebook which you can add to your notebook by copying and pasting, or by running and saving/copying the results into your active notebook (better to show all work though!). Note that if you want to save multiple fit outputs and import them, you will need to change the output image filename at the bottom of the cell!\n",
    "\n",
    "In addition to defining new fitting functions (\"DEFINED FITTING FUNCTIONS\"), you will typically need to update or modify the information contained in \"LIST OF ALL INPUTS\":\n",
    "* `fname` to load the correct data file\n",
    "* `x_name`, `x_units`, `y_name` and `y_units` to match your data file\n",
    "* `fit_function = ..` to use your defined fitting function\n",
    "* `param_names` and `guesses`: these MUST match the parameters in the defined fitting function that follow after (x,...)\n",
    "* Update any of the optional features flags as desired\n",
    "\n",
    "The datafile ``fname`` is assumed to be a four-column .csv file corresponding to x-values, x-uncertainties, y-values, y-uncertainties, with 2 header rows giving the names and units of these columns. This is the same as the output of the packed data we used last week and will continue to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1242627b-7ebc-4262-a892-815d3f4ad5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load python packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "###############################################################################\n",
    "# DEFINED FITTING FUNCTIONS\n",
    "###############################################################################\n",
    "\n",
    "def sine_func(x, amplitude, freq, phase):\n",
    "    return amplitude * np.sin(2.0 * np.pi * freq * x + phase)\n",
    "\n",
    "def offset_sine_func(x, amplitude, freq, phase, offset):\n",
    "    return (amplitude * np.sin(2.0 * np.pi * freq * x + phase)) + offset\n",
    "\n",
    "def exponential_func(x, amplitude, tau, voffset):\n",
    "    return amplitude * np.exp(x/(-1.0*tau)) + voffset\n",
    "\n",
    "###############################################################################\n",
    "# LIST OF ALL INPUTS\n",
    "###############################################################################\n",
    "\n",
    "# Name of the data file\n",
    "fname = \"sintest2_pack.csv\"\n",
    "\n",
    "# Names and units of data columns from fname\n",
    "x_name = \"Time\"\n",
    "x_units = \"s\"\n",
    "y_name = \"Voltage\"\n",
    "y_units = \"V\"\n",
    "\n",
    "# Modify to change the fitting function, parameter names and to set initial parameter guesses\n",
    "fit_function = sine_func\n",
    "param_names = (\"amplitude\", \"frequency\", \"phase\")\n",
    "guesses = (1.0, 900, 0.1)\n",
    "\n",
    "# Flags for optional features\n",
    "show_covariance_matrix = False\n",
    "set_xy_boundaries = False\n",
    "lower_x = -0.01 # these values ignored if set_xy_boundaries = False\n",
    "upper_x = 0.01\n",
    "lower_y = -1\n",
    "upper_y = 1\n",
    "\n",
    "###############################################################################\n",
    "# LOAD DATA\n",
    "###############################################################################\n",
    "\n",
    "# load the file fname and skip the first 'skiprows' rows\n",
    "data = np.loadtxt(fname, delimiter=\",\", comments=\"#\", usecols=(0, 1, 2, 3), skiprows=2)\n",
    "\n",
    "# Assign the data file columns to variables for later use\n",
    "x = data[:, 0]\n",
    "y = data[:, 2]\n",
    "y_sigma = data[:, 3]\n",
    "\n",
    "###############################################################################\n",
    "# INITIAL PLOT OF THE DATA\n",
    "###############################################################################\n",
    "\n",
    "# Define 500 points spanning the range of the x-data; for plotting smooth curves\n",
    "xtheory = np.linspace(min(x), max(x), 500)\n",
    "\n",
    "# Compare the guessed curve to the data for visual reference\n",
    "y_guess = fit_function(xtheory, *guesses)\n",
    "plt.errorbar(x, y, yerr=y_sigma, marker=\".\", linestyle=\"\", label=\"Measured data\")\n",
    "plt.plot(\n",
    "    xtheory,\n",
    "    y_guess,\n",
    "    marker=\"\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=1,\n",
    "    color=\"g\",\n",
    "    label=\"Initial parameter guesses\",\n",
    ")\n",
    "plt.xlabel(f\"{x_name} [{x_units}]\")\n",
    "plt.ylabel(f\"{y_name} [{y_units}]\")\n",
    "plt.title(r\"Comparison between the data and the intial parameter guesses\")\n",
    "plt.legend(loc=\"best\", numpoints=1)\n",
    "plt.show()\n",
    "\n",
    "# calculate the value of the model at each of the x-values of the data set\n",
    "y_fit = fit_function(x, *guesses)\n",
    "\n",
    "# Residuals are the difference between the data and theory\n",
    "residual = y - y_fit\n",
    "\n",
    "# Plot the residuals\n",
    "plt.errorbar(x, residual, yerr=y_sigma, marker=\".\", linestyle=\"\", label=\"residuals\")\n",
    "plt.xlabel(f\"{x_name} [{x_units}]\")\n",
    "plt.ylabel(f\"Residual y-y_fit [{y_units}]\")\n",
    "plt.title(\"Residuals using initial parameter guesses\")\n",
    "plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# PERFORM THE FIT AND PRINT RESULTS\n",
    "###############################################################################\n",
    "\n",
    "# Use curve_fit to perform the fit\n",
    "# fit_function: defined above to choose a specific fitting function \n",
    "# fit_params: holds the resulting fit parameters\n",
    "# fit_cov: the covariance matrix between all the parameters\n",
    "#          (used to extract fitting parameter uncertanties)\n",
    "# maxfev=10**5: maximum number of fitting procedure iterations before giving up\n",
    "# absolute_sigma=True: uncertainties are treated as absolute (not relative)\n",
    "fit_params, fit_cov = curve_fit(\n",
    "    fit_function, x, y, sigma=y_sigma, \n",
    "    p0=guesses,absolute_sigma=True, maxfev=10**5)\n",
    "\n",
    "# Define the function that calculates chi-squared\n",
    "def chi_square(fit_parameters, x, y, sigma):\n",
    "    dof = len(x) - len(fit_params)\n",
    "    return np.sum((y - fit_function(x, *fit_parameters)) ** 2 / sigma**2)/dof\n",
    "\n",
    "# Calculate and print reduced chi-squared\n",
    "chi2 = chi_square(fit_params, x, y, y_sigma)\n",
    "print(\"Chi-squared = \", chi2)\n",
    "\n",
    "# Calculate the uncertainties in the fit parameters\n",
    "fit_params_error = np.sqrt(np.diag(fit_cov))\n",
    "\n",
    "# Print the fit parameters with uncertianties\n",
    "print(\"\\nFit parameters:\")\n",
    "for i in range(len(fit_params)):\n",
    "    print(f\"   {param_names[i]} = {fit_params[i]:.3e} ± {fit_params_error[i]:.3e}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# (Optional) Print the covariance between all variables\n",
    "if show_covariance_matrix:\n",
    "    print(\"Covariance between fit parameters:\")\n",
    "    for i, fit_covariance in enumerate(fit_cov):\n",
    "        for j in range(i+1,len(fit_covariance)):\n",
    "            print(f\"   {param_names[i]} and {param_names[j]}: {fit_cov[i,j]:.3e}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# residual is the difference between the data and model\n",
    "x_fitfunc = np.linspace(min(x), max(x), len(x))\n",
    "y_fitfunc = fit_function(x_fitfunc, *fit_params)\n",
    "y_fit = fit_function(x, *fit_params)\n",
    "residual = y-y_fit\n",
    "\n",
    "###############################################################################\n",
    "# PRODUCE A MULTIPANEL PLOT, WITH SCATTER PLOT, RESIDUALS AND RESIDUALS HISTOGRAM\n",
    "###############################################################################\n",
    "\n",
    "# The size of the canvas\n",
    "fig = plt.figure(figsize=(7,10))\n",
    "\n",
    "# The scatter plot\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.errorbar(x,y,yerr=y_sigma,marker='.',linestyle='',label=\"Measured data\")\n",
    "ax1.plot(x_fitfunc, y_fitfunc, marker=\"\", linestyle=\"-\", linewidth=2,color=\"r\", label=\"Fit\")\n",
    "ax1.set_xlabel(f\"{x_name} [{x_units}]\")\n",
    "ax1.set_ylabel(f\"{y_name} [{y_units}]\")\n",
    "ax1.set_title('Best Fit of Function to Data')\n",
    "\n",
    "# (Optional) set the x and y boundaries of your plot\n",
    "if set_xy_boundaries:\n",
    "    plt.xlim(lower_x,upper_x)\n",
    "    plt.ylim(lower_y,upper_y)\n",
    "# Show the legend. loc='best' places it where the date are least obstructed\n",
    "ax1.legend(loc='best',numpoints=1)\n",
    "\n",
    "# The residuals plot\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.errorbar(x, residual, yerr=y_sigma,marker='.', linestyle='', label=\"Residual (y-y_fit)\")\n",
    "ax2.hlines(0,np.min(x),np.max(x),lw=2,alpha=0.8)\n",
    "ax2.set_xlabel(f\"{x_name} [{x_units}]\")\n",
    "ax2.set_ylabel(f\"y-y_fit [{y_units}]\")\n",
    "ax2.set_title('Residuals for the Best Fit')\n",
    "ax2.legend(loc='best',numpoints=1)\n",
    "\n",
    "# Histogram of the residuals -- commented out in 2025; deemed extraneous, look at distribution of residuals in above plot\n",
    "# ax3 = fig.add_subplot(313)\n",
    "# hist,bins = np.histogram(residual,bins=30)\n",
    "# ax3.bar(bins[:-1],hist,width=bins[1]-bins[0])\n",
    "# ax3.set_ylim(0,1.2*np.max(hist))\n",
    "# ax3.set_xlabel(f\"y-y_fit [{y_units}]\")\n",
    "# ax3.set_ylabel('Number of occurences')\n",
    "# ax3.set_title('Histogram of the Residuals')\n",
    "\n",
    "# Save a copy of the figure as a png \n",
    "plt.savefig('FittingResults.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
