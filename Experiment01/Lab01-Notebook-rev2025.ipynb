{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5831b5a-2d29-4176-abc7-73c1b16a3977",
   "metadata": {},
   "source": [
    "# Experiment 01 - Introduction to the Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828d089b-a0f0-43e9-9d32-b22a2ebea1ad",
   "metadata": {},
   "source": [
    "Date:\n",
    "\n",
    "Name:\n",
    "\n",
    "Partner's name:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3147f3-9b0c-4cd3-8e7e-88a45a72eebc",
   "metadata": {},
   "source": [
    "This first Jupyter notebook will be fairly guided, but you should add your own comments wherever you feel it is appropriate. In future labs you will be expected to take notes as you go about what you are doing and your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18b7b95-81c5-4436-af0c-0d85b43f5e56",
   "metadata": {},
   "source": [
    "# Measurements of Variable Resistor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4736356b-5204-47b1-b928-b85cba185235",
   "metadata": {},
   "source": [
    "Describe your measurements of the Variable Resistor with the DMM. If you took notes on paper, take a photo of your notes and include them here. Make sure you take a final recording after adjusting the screw as this will determine the ratio of the voltage divider we will use for the rest of the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f5fe5a-7fee-4104-a37e-164d7a4af63e",
   "metadata": {},
   "source": [
    "Enter your resistance measurements here to calculate the voltage divider ratio. Make sure that \"$R_{out}$\" is the resistance measured across the 2 legs you will measure a voltage across with the oscilloscope.\n",
    "\n",
    "The uncertainty in the voltage divider ratio is also calculated as: $$\\delta ratio = ratio\\sqrt{(\\frac{\\delta R_{tot}}{R_{tot}})^2+(\\frac{\\delta R_{out}}{R_{out}})^2}$$\n",
    "*(working with uncertainties like this should be familiar from PHYS 219!)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93998c1-78a6-4ced-9834-da0aa882f24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Replace values below with your resistance measurements\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# import the  library numpy  and rename it  np\n",
    "import numpy as np\n",
    "import array\n",
    "\n",
    "Rtot=10.44*1000 # Resistance between outer legs\n",
    "dRtot=0.01*1000 # Uncertainty in the resistance between the outer legs\n",
    "Rout=1.974*1000 # Resistance between middle and outer leg (use the pair you will measure with the oscilloscope)\n",
    "dRout=0.001*1000 # Uncertainty in the resistance between the middle and outer leg\n",
    "\n",
    "ratio=Rout/Rtot\n",
    "dratio=ratio*np.sqrt((dRtot/Rtot)**2+(dRout/Rout)**2)\n",
    "print(\"Ratio = \",ratio,\" +/- \",dratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103385ae-3565-4fa8-8ac7-782916b7bfbd",
   "metadata": {},
   "source": [
    "# Oscilloscope measurement and fitting tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5945139-27ff-46a1-85e7-57df95f4867e",
   "metadata": {},
   "source": [
    "Following the instructions for this lab, take measurements of a sine wave output of the function generator and voltage divider output and use the generalized fitting routine we will use for this course to assess the quality of the output (i.e. how close is it to a clean sine wave), and determine where any issues lie so you will be familiar with a variety of potential pitfalls in future labs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043ceedc-7c18-41e2-a7a1-54e962b0d7a9",
   "metadata": {},
   "source": [
    "## Data set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81febedd-25b9-44f0-b662-5a1cf3c56ce2",
   "metadata": {},
   "source": [
    "Record your observations of the oscilloscope measurement of the signal according to the directions in the lab instructions and save the data (note the filename here or in a paper logbook)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b005897-8131-41f7-aaca-6f74ba21eb88",
   "metadata": {},
   "source": [
    "### Upload and start working with data set 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b7004b-be69-45b9-a4a6-8bbb5485d1c5",
   "metadata": {},
   "source": [
    "You can find the upload button on the upper right, above your list of directories. You should upload your data files into the same subdirectory as this notebook.\n",
    "\n",
    "The first piece of Python code below is written to produce two plots of your data, one as voltage versus time, and one as voltage versus index number.\n",
    "\n",
    "For the code to work, you will need to modify the filename used in the line `fname = 'vdivCH1.csv'`\n",
    "\n",
    "You should also modify the title to make it more informative. We'll try to keep all of these blocks to be modified near the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff901929-ed2c-4c0d-834b-d3b28bca5841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the  library numpy  and rename it  np\n",
    "import numpy as np\n",
    "import array\n",
    "\n",
    "# import the library matplotlib and rename it plt\n",
    "import matplotlib.pyplot as plt\n",
    "#name  the input file  with the data\n",
    "fname = 'vdivCH1.csv'\n",
    "title = 'My Raw MicSig Data'\n",
    "\n",
    "# read in data - the file is assumed to be in csv format (comma separated variables). \n",
    "#Files need to be specified with a full path OR they have to be saved in the same folder \n",
    "#as the script\n",
    "data = np.loadtxt(fname, delimiter=',', comments='#',usecols=(3,4),skiprows=1)\n",
    "# access the data columns and assign variables xraw and yraw\n",
    "#generate  an array  xraw  which is the first  column  of  data.  Note the first column is \n",
    "#indexed as  zero.\n",
    "xraw = data[:,0]\n",
    "#generate  an array  yraw  which is the second  column  of  data  (index  1)\n",
    "yraw = data[:,1]\n",
    "\n",
    "indexraw=np.arange(len(xraw))\n",
    "\n",
    "\n",
    "# plot the data\n",
    "plt.scatter(xraw, yraw,marker='.')\n",
    "# add axis labels\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n",
    "# plot the data versus index\n",
    "plt.scatter(indexraw,yraw,marker='.')\n",
    "## marker='o' : use markers to indicate each data point (x_1,y_1),(x_2,y_2)\n",
    "## linestyle= '' : no line is drawn to connect the data points\n",
    "## linestyle= '-' : a line is drawn to connect the data points\n",
    "\n",
    "# add axis labels\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Voltage (V)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6848f76a-d438-44e8-9028-8e9a988d6406",
   "metadata": {},
   "source": [
    "You will notice in the second plot that the index value goes very high; there are 87500 data points (index 0 to 87499).\n",
    "This is a big number that we will take advantage of in two ways. First, you can zoom in on the data to closely examine the noise. Second, we will average neighbouring points together, which will make the number of points plotted a bit more manageable, and gain some statistical advantage by averaging.\n",
    "\n",
    "Let's start by examining the noise. First, make some notes in a cell below this one, about what you observe in the plot. Then, use the Python code below to zoom in on a minimum or maximum of the sine wave, restricting your plot to a narrow time range where the voltage does not vary much. You will need to adjust the x (`indexraw_min` and `indexraw_max`) and y limits to zoom in on the selection (`yregion_min` and `yregion_max`) until you see a slice of data that is flat and just shows the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b706f21-672e-4144-97b9-1747bb7a488e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the MicSig files contain 87,500 data points (index runs from 0 to 87499)\n",
    "# here you can zoom in on some data to determine the noise\n",
    "# pick a part of the curve that is flat\n",
    "\n",
    "# choose the data range you want to examine\n",
    "indexraw_min = 67000\n",
    "indexraw_max = 67600\n",
    "\n",
    "yregion_min=-5.2\n",
    "yregion_max=-4.8\n",
    "\n",
    "# change axis limits corresponding to where the data is in the above range\n",
    "plt.xlim(indexraw_min,indexraw_max)\n",
    "plt.ylim(yregion_min,yregion_max)\n",
    "\n",
    "# plot the data versus index\n",
    "plt.scatter(indexraw,yraw,marker='.')\n",
    "\n",
    "# This next command displays the index plot. \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605c56c0-c1e4-42c6-a915-9ac8a40000da",
   "metadata": {},
   "source": [
    "Once you have chosen a data range that is flat and shows just the noise, we can examine the noise statistically. The code below calculates the mean and standard deviation of this segment of data. It also produces a histogram of the data, so you can see what the distribution looks like. Note that this piece of code remembers your choice for the data range (`indexraw_min` and `indexraw_max`)\n",
    "\n",
    "You might want to adjust the number of bins and histogram plotting limit to examine the distribution carefully.\n",
    "\n",
    "Enter some notes in a cell below about what you observe in the distribution, and the values of mean and standard deviation. Note that the standard deviation provides a rough estimate of the uncertainty in each individual data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26bd5342-ec98-4f74-8855-3e7bcdc812e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate and display the mean and standard deviation of the data that you have zoomed in on.\n",
    "y_ave = np.mean(yraw[indexraw_min:indexraw_max])\n",
    "y_std = np.std(yraw[indexraw_min:indexraw_max])\n",
    "print('mean = ',y_ave,y_std)\n",
    "print('standard deviation = ', y_std)\n",
    "\n",
    "\n",
    "hist,bins = np.histogram(yraw[indexraw_min:indexraw_max],bins=20)\n",
    "plt.bar(bins[:-1],hist,width=bins[1]-bins[0])\n",
    "plt.ylim(0,1.2*np.max(hist))\n",
    "plt.xlabel('y_raw (Volts)')\n",
    "plt.ylabel('Number of occurences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a361bc91-1a0c-415b-a61b-dca35e080d78",
   "metadata": {},
   "source": [
    "Once you have examined the noise and determined a reasonable estimate for the standard deviation, we can do some averaging to reduce the uncertainty of individual data points.\n",
    "\n",
    "For example, if you average 100 neighbouring data points, the uncertainty in that average is $\\sqrt{100}$ smaller that the standard deviation of the individual data point.\n",
    "So, you reduce uncertainty by a factor of 10. The cost for this is that you lose time resolution, but you have much more data and more time resolution that you need, so that is fine. \n",
    "\n",
    "Note that the code below makes use of the standard deviation that you found in the last piece of code.\n",
    "\n",
    "We refer to this averaging process as \"packing\" the data, since it also serves to reduce the number of data points to something more manageable.\n",
    "\n",
    "The code below does this packing. Try playing around with `npac`, the number of data points being averaged together. Compare what you see after packing to the plot of raw data. Don't forget to keep taking notes on what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f72900-b6c0-499b-a94e-6b98ad269545",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This block packs your data and saves it. \n",
    "\"\"\"\n",
    "\n",
    "npac=100 # define packing factor  npac\n",
    "title='My Packed MicSig Data' # give your graph a title\n",
    "output_name = 'vdivCH1-packed.csv' # provide an output filename for the packed data\n",
    "\n",
    "#define a function  to pack the data\n",
    "def pack(A,p):\n",
    "  # A is an array, and p is the packing factor\n",
    "  B = np.zeros(len(A)//p)\n",
    "  i = 1\n",
    "  while i-1<len(B):\n",
    "    B[i-1] = np.mean(A[p*(i-1):p*i])\n",
    "    i += 1\n",
    "  return B\n",
    "# pack the data\n",
    "x=pack(xraw,npac)\n",
    "y=pack(yraw,npac)\n",
    "\n",
    "#create a vector that also has the integer index (index = 0,1,2 ... length-1)\n",
    "length=len(x)\n",
    "#print(length)\n",
    "index = np.arange(length)\n",
    "\n",
    "#create a vector that contains fixed uncertainty for x values (in this case set to zero\n",
    "sigmax = [0]*length\n",
    "#print(sigmax)\n",
    "\n",
    "#Create a vector that contains uncertainty of averaged y values. \n",
    "#sigmayraw is your estimate of the uncertainty in individual raw data points\n",
    "\n",
    "#Here it is taking that value from your previous statistics code, but you can also enter a value by hand\n",
    "#sigmaymean is the uncertainty of y after averaging npac points together\n",
    "#sigmay is an array of uncertainties, all of the same value as sigmaymean\n",
    "sigmayraw = y_std\n",
    "sigmaymean = sigmayraw/np.sqrt(npac)\n",
    "sigmay = [sigmaymean]*length\n",
    "\n",
    "# plot the data\n",
    "plt.errorbar(x, y,yerr=sigmay,marker='.',linestyle='')\n",
    "# add axis labels\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n",
    "# Import pandas for using Dataframes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create Array and output as CSV file with Headers\n",
    "\n",
    "header = [np.array(['Time','u[time]','Voltage','u[Voltage]']), \n",
    "np.array(['(sec)','(sec)','(V)','(V)'])]\n",
    "d1 = [x , sigmax , y , sigmay]\n",
    "d1_a = np.array(d1)\n",
    "df = pd.DataFrame(np.transpose(d1_a), columns=header )   \n",
    "    \n",
    "# print(df)\n",
    "\n",
    "csv_data = df.to_csv(output_name, index = False)\n",
    "print('Packed Data Stored in ', output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e87c9be-7134-4df7-a984-d26dd08b393c",
   "metadata": {},
   "source": [
    "### Introduction to fitting: load the data and make a guess\n",
    "\n",
    "Now we will fit a model to the data, we will walk through the steps for this first data set, then move on to a more compact and generalized version you will use throughout the course.\n",
    "\n",
    "The data set needs to be in a four-column .csv file, like the one you produced when you examined your data and packed it:\n",
    "* `fname` is assumed to be in a four-column .csv file.\n",
    "* In the following code, `skiprows=2` indicates that the first two rows in `fname` are headers (names and units)\n",
    "\n",
    "<center>data = np.loadtxt(fname, .. , skiprows=2)</center>\n",
    "\n",
    "* The four columns are x-values, x-uncertainties, y-values, y-uncertainties.\n",
    "* The .csv file must be in the same folder as notebook. otherwise the full file extension must be added\n",
    "to fname: e.g. fname = 'folder/subfolder/subsubfolder/file.csv'\n",
    "\n",
    "You will typically need to update or modify the information contained in \"LIST OF ALL INPUTS\":\n",
    "* `fname` to load the correct data file (for this example, it will be the packed data from the previous code cell)\n",
    "* `x_name`, `x_units`, `y_name` and `y_units` to match your data file\n",
    "* `fit_function = ..` to use your defined fitting function (for this example start with `sine_func`)\n",
    "* `param_names` and `guesses` (your guesses can be guided by what you expect the parameters to be; hint: check your notes for what you set on the function generator!)\n",
    "* Update any of the optional features flags as desired\n",
    "For future experiments you will have additional options for fitting functions. If you want to modify the model (for example here, there is a sine wave with an offset added) you can define new fitting functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f2f0f2-7a65-4c6f-930a-aef943b53329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load python packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "###############################################################################\n",
    "# DEFINED FITTING FUNCTIONS\n",
    "###############################################################################\n",
    "\n",
    "def sine_func(x, amplitude, freq, phase):\n",
    "    return amplitude * np.sin(2.0 * np.pi * freq * x + phase)\n",
    "\n",
    "def offset_sine_func(x, amplitude, freq, phase, offset):\n",
    "    return (amplitude * np.sin(2.0 * np.pi * freq * x + phase)) + offset\n",
    "\n",
    "###############################################################################\n",
    "# LIST OF ALL INPUTS\n",
    "###############################################################################\n",
    "\n",
    "# Name of the data file\n",
    "fname = \"vdivCH1-packed.csv\"\n",
    "\n",
    "# Names and units of data columns from fname\n",
    "x_name = \"Time\"\n",
    "x_units = \"s\"\n",
    "y_name = \"Voltage\"\n",
    "y_units = \"V\"\n",
    "\n",
    "# Modify to change the fitting function, parameter names and to set initial parameter guesses\n",
    "fit_function = sine_func\n",
    "param_names = (\"amplitude\", \"frequency\", \"phase\")\n",
    "guesses = (4.5, 900, -1.7)\n",
    "\n",
    "# Flags for optional features\n",
    "show_covariance_matrix = False\n",
    "set_xy_boundaries = False\n",
    "lower_x = -0.01 # these values ignored if set_xy_boundaries = False\n",
    "upper_x = 0.01\n",
    "lower_y = -1\n",
    "upper_y = 1\n",
    "\n",
    "###############################################################################\n",
    "# LOAD DATA\n",
    "###############################################################################\n",
    "\n",
    "# load the file fname and skip the first 'skiprows' rows\n",
    "data = np.loadtxt(fname, delimiter=\",\", comments=\"#\", usecols=(0, 1, 2, 3), skiprows=2)\n",
    "\n",
    "# Assign the data file columns to variables for later use\n",
    "x = data[:, 0]\n",
    "y = data[:, 2]\n",
    "y_sigma = data[:, 3]\n",
    "\n",
    "###############################################################################\n",
    "# INITIAL PLOT OF THE DATA\n",
    "###############################################################################\n",
    "\n",
    "# Define 500 points spanning the range of the x-data; for plotting smooth curves\n",
    "xtheory = np.linspace(min(x), max(x), 500)\n",
    "\n",
    "# Compare the guessed curve to the data for visual reference\n",
    "y_guess = fit_function(xtheory, *guesses)\n",
    "plt.errorbar(x, y, yerr=y_sigma, marker=\".\", linestyle=\"\", label=\"Measured data\")\n",
    "plt.plot(\n",
    "    xtheory,\n",
    "    y_guess,\n",
    "    marker=\"\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=1,\n",
    "    color=\"g\",\n",
    "    label=\"Initial parameter guesses\",\n",
    ")\n",
    "plt.xlabel(f\"{x_name} [{x_units}]\")\n",
    "plt.ylabel(f\"{y_name} [{y_units}]\")\n",
    "plt.title(r\"Comparison between the data and the intial parameter guesses\")\n",
    "plt.legend(loc=\"best\", numpoints=1)\n",
    "plt.show()\n",
    "\n",
    "# calculate the value of the model at each of the x-values of the data set\n",
    "y_fit = fit_function(x, *guesses)\n",
    "\n",
    "# Residuals are the difference between the data and theory\n",
    "residual = y - y_fit\n",
    "\n",
    "# Plot the residuals\n",
    "plt.errorbar(x, residual, yerr=y_sigma, marker=\".\", linestyle=\"\", label=\"residuals\")\n",
    "plt.xlabel(f\"{x_name} [{x_units}]\")\n",
    "plt.ylabel(f\"Residual y-y_fit [{y_units}]\")\n",
    "plt.title(\"Residuals using initial parameter guesses\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6e72cc-299c-4460-b8db-a5f9d9eac58a",
   "metadata": {},
   "source": [
    "Take a look at the residuals.\n",
    "\n",
    "The way least squares fitting works is to look at the difference between your data and the model. To do this, you calculate the value of the model at each of the \"x values\" in your data set. In this case, that means calculating the model sine function at every value of time in your data set.\n",
    "\n",
    "The difference between each measured \"y value\" (Voltage in your data) and the model value is called the residuals. The code below calculates the residuals and plots them.\n",
    "\n",
    "The smaller the residuals, the better the fit between data and model.\n",
    "\n",
    "Note that since your data is sinusoidal, and your model is sinusoidal, the residuals might also look sinusoidal. The goal of fitting is to find parameters that make the residuals as small as possible and with no obvious shape. You can tinker with the parameters a bit to see how this influences the residuals."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42196d3-07aa-4a0b-a90a-17bd035bdfa5",
   "metadata": {},
   "source": [
    "### Perform the fit\n",
    "\n",
    "The next section then performs a non-linear least squares fit of the defined function to the data using a routine called `curvefit` from the SciPy library. The routine is fairly robust, but the better the initial guess, and the better quality the data the less likely it will fail. In future, these two code blocks will be presented together.\n",
    "\n",
    "This code block outputs the following:\n",
    "* The reduced $\\chi^2$ value (\"reduced\" meaning the $chi^2$ per degrees of freedom of the fit)\n",
    "* Each parameter and its uncertainty from the fit\n",
    "* Plots of the data with the fit, the residuals, and a histogram of the residuals (ideally the residuals will be centred around zero, small relative to the uncertainty, and structureless)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842b18d-728b-4e57-99e5-873cc59c8be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# PERFORM THE FIT AND PRINT RESULTS\n",
    "###############################################################################\n",
    "\n",
    "# Use curve_fit to perform the fit\n",
    "# fit_function: defined above to choose a specific fitting function \n",
    "# fit_params: holds the resulting fit parameters\n",
    "# fit_cov: the covariance matrix between all the parameters\n",
    "#          (used to extract fitting parameter uncertanties)\n",
    "# maxfev=10**5: maximum number of fitting procedure iterations before giving up\n",
    "# absolute_sigma=True: uncertainties are treated as absolute (not relative)\n",
    "fit_params, fit_cov = curve_fit(\n",
    "    fit_function, x, y, sigma=y_sigma, \n",
    "    p0=guesses,absolute_sigma=True, maxfev=10**5)\n",
    "\n",
    "# Define the function that calculates chi-squared\n",
    "def chi_square(fit_parameters, x, y, sigma):\n",
    "    dof = len(x) - len(fit_params)\n",
    "    return np.sum((y - fit_function(x, *fit_parameters)) ** 2 / sigma**2)/dof\n",
    "\n",
    "# Calculate and print reduced chi-squared\n",
    "chi2 = chi_square(fit_params, x, y, y_sigma)\n",
    "print(\"Chi-squared = \", chi2)\n",
    "\n",
    "# Calculate the uncertainties in the fit parameters\n",
    "fit_params_error = np.sqrt(np.diag(fit_cov))\n",
    "\n",
    "# Print the fit parameters with uncertianties\n",
    "print(\"\\nFit parameters:\")\n",
    "for i in range(len(fit_params)):\n",
    "    print(f\"   {param_names[i]} = {fit_params[i]:.3e} ± {fit_params_error[i]:.3e}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# (Optional) Print the covariance between all variables\n",
    "if show_covariance_matrix:\n",
    "    print(\"Covariance between fit parameters:\")\n",
    "    for i, fit_covariance in enumerate(fit_cov):\n",
    "        for j in range(i+1,len(fit_covariance)):\n",
    "            print(f\"   {param_names[i]} and {param_names[j]}: {fit_cov[i,j]:.3e}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# residual is the difference between the data and model\n",
    "x_fitfunc = np.linspace(min(x), max(x), len(x))\n",
    "y_fitfunc = fit_function(x_fitfunc, *fit_params)\n",
    "y_fit = fit_function(x, *fit_params)\n",
    "residual = y-y_fit\n",
    "\n",
    "###############################################################################\n",
    "# PRODUCE A MULTIPANEL PLOT, WITH SCATTER PLOT, RESIDUALS AND RESIDUALS HISTOGRAM\n",
    "###############################################################################\n",
    "\n",
    "# The size of the canvas\n",
    "fig = plt.figure(figsize=(7,15))\n",
    "\n",
    "# The scatter plot\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.errorbar(x,y,yerr=y_sigma,marker='.',linestyle='',label=\"Measured data\")\n",
    "ax1.plot(x_fitfunc, y_fitfunc, marker=\"\", linestyle=\"-\", linewidth=2,color=\"r\", label=\"Fit\")\n",
    "ax1.set_xlabel(f\"{x_name} [{x_units}]\")\n",
    "ax1.set_ylabel(f\"{y_name} [{y_units}]\")\n",
    "ax1.set_title('Best Fit of Function to Data')\n",
    "\n",
    "# (Optional) set the x and y boundaries of your plot\n",
    "if set_xy_boundaries:\n",
    "    plt.xlim(lower_x,upper_x)\n",
    "    plt.ylim(lower_y,upper_y)\n",
    "# Show the legend. loc='best' places it where the date are least obstructed\n",
    "ax1.legend(loc='best',numpoints=1)\n",
    "\n",
    "# The residuals plot\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.errorbar(x, residual, yerr=y_sigma,marker='.', linestyle='', label=\"Residual (y-y_fit)\")\n",
    "ax2.hlines(0,np.min(x),np.max(x),lw=2,alpha=0.8)\n",
    "ax2.set_xlabel(f\"{x_name} [{x_units}]\")\n",
    "ax2.set_ylabel(f\"y-y_fit [{y_units}]\")\n",
    "ax2.set_title('Residuals for the Best Fit')\n",
    "ax2.legend(loc='best',numpoints=1)\n",
    "\n",
    "# Histogram of the residuals -> commented out in 2025 as extraneous; plot of residuals more informative\n",
    "#ax3 = fig.add_subplot(313)\n",
    "#hist,bins = np.histogram(residual,bins=30)\n",
    "#ax3.bar(bins[:-1],hist,width=bins[1]-bins[0])\n",
    "#ax3.set_ylim(0,1.2*np.max(hist))\n",
    "#ax3.set_xlabel(f\"y-y_fit [{y_units}]\")\n",
    "#ax3.set_ylabel('Number of occurences')\n",
    "#ax3.set_title('Histogram of the Residuals')\n",
    "\n",
    "# Save a copy of the figure as a png \n",
    "plt.savefig('FittingResults.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185414e7-355b-4d4f-adb5-b1f275fb51f9",
   "metadata": {},
   "source": [
    "Comment on the residuals and quality of the fit. What does this say about the data you aquired? About the model you are using to describe the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74412b2-c86c-4aad-a427-4852edef8d51",
   "metadata": {},
   "source": [
    "## Data set 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b297a089-f5ea-4430-9fc9-5d58a1309430",
   "metadata": {},
   "source": [
    "Record your observations of the oscilloscope measurement of the signal according to the directions in the lab instructions and save the data (note the filename here or in a paper logbook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a01711-d263-4ce3-be4f-0a76d34a0b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the  library numpy  and rename it  np\n",
    "import numpy as np\n",
    "import array\n",
    "\n",
    "# import the library matplotlib and rename it plt\n",
    "import matplotlib.pyplot as plt\n",
    "#name  the input file  with the data\n",
    "fname = 'vdivCH1.csv'\n",
    "title = 'My Raw MicSig Data'\n",
    "\n",
    "# the MicSig files contain 87,500 data points (index runs from 0 to 87499)\n",
    "# here you can zoom in on some data to determine the noise\n",
    "# pick a part of the curve that is flat\n",
    "\n",
    "# choose the data range you want to examine and set the y-range\n",
    "indexraw_min = 67000\n",
    "indexraw_max = 67600\n",
    "\n",
    "yregion_min=-5.2\n",
    "yregion_max=-4.8\n",
    "\n",
    "# read in data - the file is assumed to be in csv format (comma separated variables). \n",
    "#Files need to be specified with a full path OR they have to be saved in the same folder \n",
    "#as the script\n",
    "data = np.loadtxt(fname, delimiter=',', comments='#',usecols=(3,4),skiprows=1)\n",
    "# access the data columns and assign variables xraw and yraw\n",
    "#generate  an array  xraw  which is the first  column  of  data.  Note the first column is \n",
    "#indexed as  zero.\n",
    "xraw = data[:,0]\n",
    "#generate  an array  yraw  which is the second  column  of  data  (index  1)\n",
    "yraw = data[:,1]\n",
    "\n",
    "indexraw=np.arange(len(xraw))\n",
    "\n",
    "\n",
    "# plot the data\n",
    "plt.scatter(xraw, yraw,marker='.')\n",
    "# add axis labels\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n",
    "# plot the data versus index\n",
    "plt.scatter(indexraw,yraw,marker='.')\n",
    "## marker='o' : use markers to indicate each data point (x_1,y_1),(x_2,y_2)\n",
    "## linestyle= '' : no line is drawn to connect the data points\n",
    "## linestyle= '-' : a line is drawn to connect the data points\n",
    "\n",
    "# add axis labels\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Voltage (V)')\n",
    "\n",
    "# change axis limits corresponding to where the data is in the above range\n",
    "plt.xlim(indexraw_min,indexraw_max)\n",
    "plt.ylim(yregion_min,yregion_max)\n",
    "\n",
    "# plot the data versus index\n",
    "plt.scatter(indexraw,yraw,marker='.')\n",
    "\n",
    "# This next command displays the index plot. \n",
    "plt.show()\n",
    "\n",
    "#calculate and display the mean and standard deviation of the data that you have zoomed in on.\n",
    "y_ave = np.mean(yraw[indexraw_min:indexraw_max])\n",
    "y_std = np.std(yraw[indexraw_min:indexraw_max])\n",
    "print('mean = ',y_ave,y_std)\n",
    "print('standard deviation = ', y_std)\n",
    "\n",
    "\n",
    "hist,bins = np.histogram(yraw[indexraw_min:indexraw_max],bins=20)\n",
    "plt.bar(bins[:-1],hist,width=bins[1]-bins[0])\n",
    "plt.ylim(0,1.2*np.max(hist))\n",
    "plt.xlabel('y_raw (Volts)')\n",
    "plt.ylabel('Number of occurences')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e381624-c755-4b6c-878b-9f26dff9b9a0",
   "metadata": {},
   "source": [
    "Once you've examined the data and determined uncertainties, you can now \"pack\" the data. Set the packing factor `npac` and don't forget to change the filename `output_name` to save the packed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d648c2b-a2e7-48ec-9b01-443ea4bbb430",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This block packs your data and saves it. \n",
    "\"\"\"\n",
    "\n",
    "npac=100 # define packing factor  npac\n",
    "title='My Packed MicSig Data' # give your graph a title\n",
    "output_name = 'vdivCH1-packed.csv' # provide an output filename for the packed data\n",
    "\n",
    "#define a function  to pack the data\n",
    "def pack(A,p):\n",
    "  # A is an array, and p is the packing factor\n",
    "  B = np.zeros(len(A)//p)\n",
    "  i = 1\n",
    "  while i-1<len(B):\n",
    "    B[i-1] = np.mean(A[p*(i-1):p*i])\n",
    "    i += 1\n",
    "  return B\n",
    "# pack the data\n",
    "x=pack(xraw,npac)\n",
    "y=pack(yraw,npac)\n",
    "\n",
    "#create a vector that also has the integer index (index = 0,1,2 ... length-1)\n",
    "length=len(x)\n",
    "#print(length)\n",
    "index = np.arange(length)\n",
    "\n",
    "#create a vector that contains fixed uncertainty for x values (in this case set to zero\n",
    "sigmax = [0]*length\n",
    "#print(sigmax)\n",
    "\n",
    "#Create a vector that contains uncertainty of averaged y values. \n",
    "#sigmayraw is your estimate of the uncertainty in individual raw data points\n",
    "\n",
    "#Here it is taking that value from your previous statistics code, but you can also enter a value by hand\n",
    "#sigmaymean is the uncertainty of y after averaging npac points together\n",
    "#sigmay is an array of uncertainties, all of the same value as sigmaymean\n",
    "sigmayraw = y_std\n",
    "sigmaymean = sigmayraw/np.sqrt(npac)\n",
    "sigmay = [sigmaymean]*length\n",
    "\n",
    "# plot the data\n",
    "plt.errorbar(x, y,yerr=sigmay,marker='.',linestyle='')\n",
    "# add axis labels\n",
    "plt.xlabel('Time (sec)')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.title(title)\n",
    "plt.show()\n",
    "\n",
    "# Import pandas for using Dataframes\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create Array and output as CSV file with Headers\n",
    "\n",
    "header = [np.array(['Time','u[time]','Voltage','u[Voltage]']), \n",
    "np.array(['(sec)','(sec)','(V)','(V)'])]\n",
    "d1 = [x , sigmax , y , sigmay]\n",
    "d1_a = np.array(d1)\n",
    "df = pd.DataFrame(np.transpose(d1_a), columns=header )   \n",
    "    \n",
    "# print(df)\n",
    "\n",
    "csv_data = df.to_csv(output_name, index = False)\n",
    "print('Packed Data Stored in ', output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c504f13f-491f-40d2-a087-36bc59f577f4",
   "metadata": {},
   "source": [
    "Use the full generalized fitting routine to fit a function (sine) to the data and plot the result and the residuals. Make sure to update the following variables:\n",
    "* `fname` to load the correct data file\n",
    "* `x_name`, `x_units`, `y_name` and `y_units` to match your data file\n",
    "* `fit_function = ..` to use your defined fitting function\n",
    "* `param_names` and `guesses`\n",
    "* Update any of the optional features flags as desired"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6121704-16bc-47f2-967a-cf7018e23a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load python packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "###############################################################################\n",
    "# DEFINED FITTING FUNCTIONS\n",
    "###############################################################################\n",
    "\n",
    "def sine_func(x, amplitude, freq, phase):\n",
    "    return amplitude * np.sin(2.0 * np.pi * freq * x + phase)\n",
    "\n",
    "def offset_sine_func(x, amplitude, freq, phase, offset):\n",
    "    return (amplitude * np.sin(2.0 * np.pi * freq * x + phase)) + offset\n",
    "\n",
    "###############################################################################\n",
    "# LIST OF ALL INPUTS\n",
    "###############################################################################\n",
    "\n",
    "# Name of the data file\n",
    "fname = \"sintest2_pack.csv\"\n",
    "\n",
    "# Names and units of data columns from fname\n",
    "x_name = \"Time\"\n",
    "x_units = \"s\"\n",
    "y_name = \"Voltage\"\n",
    "y_units = \"V\"\n",
    "\n",
    "# Modify to change the fitting function, parameter names and to set initial parameter guesses\n",
    "fit_function = sine_func\n",
    "param_names = (\"amplitude\", \"frequency\", \"phase\")\n",
    "guesses = (1.0, 900, 0.1)\n",
    "\n",
    "# Flags for optional features\n",
    "show_covariance_matrix = False\n",
    "set_xy_boundaries = False\n",
    "lower_x = -0.01 # these values ignored if set_xy_boundaries = False\n",
    "upper_x = 0.01\n",
    "lower_y = -1\n",
    "upper_y = 1\n",
    "\n",
    "###############################################################################\n",
    "# LOAD DATA\n",
    "###############################################################################\n",
    "\n",
    "# load the file fname and skip the first 'skiprows' rows\n",
    "data = np.loadtxt(fname, delimiter=\",\", comments=\"#\", usecols=(0, 1, 2, 3), skiprows=2)\n",
    "\n",
    "# Assign the data file columns to variables for later use\n",
    "x = data[:, 0]\n",
    "y = data[:, 2]\n",
    "y_sigma = data[:, 3]\n",
    "\n",
    "###############################################################################\n",
    "# INITIAL PLOT OF THE DATA\n",
    "###############################################################################\n",
    "\n",
    "# Define 500 points spanning the range of the x-data; for plotting smooth curves\n",
    "xtheory = np.linspace(min(x), max(x), 500)\n",
    "\n",
    "# Compare the guessed curve to the data for visual reference\n",
    "y_guess = fit_function(xtheory, *guesses)\n",
    "plt.errorbar(x, y, yerr=y_sigma, marker=\".\", linestyle=\"\", label=\"Measured data\")\n",
    "plt.plot(\n",
    "    xtheory,\n",
    "    y_guess,\n",
    "    marker=\"\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=1,\n",
    "    color=\"g\",\n",
    "    label=\"Initial parameter guesses\",\n",
    ")\n",
    "plt.xlabel(f\"{x_name} [{x_units}]\")\n",
    "plt.ylabel(f\"{y_name} [{y_units}]\")\n",
    "plt.title(r\"Comparison between the data and the intial parameter guesses\")\n",
    "plt.legend(loc=\"best\", numpoints=1)\n",
    "plt.show()\n",
    "\n",
    "# calculate the value of the model at each of the x-values of the data set\n",
    "y_fit = fit_function(x, *guesses)\n",
    "\n",
    "# Residuals are the difference between the data and theory\n",
    "residual = y - y_fit\n",
    "\n",
    "# Plot the residuals\n",
    "plt.errorbar(x, residual, yerr=y_sigma, marker=\".\", linestyle=\"\", label=\"residuals\")\n",
    "plt.xlabel(f\"{x_name} [{x_units}]\")\n",
    "plt.ylabel(f\"Residual y-y_fit [{y_units}]\")\n",
    "plt.title(\"Residuals using initial parameter guesses\")\n",
    "plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# PERFORM THE FIT AND PRINT RESULTS\n",
    "###############################################################################\n",
    "\n",
    "# Use curve_fit to perform the fit\n",
    "# fit_function: defined above to choose a specific fitting function \n",
    "# fit_params: holds the resulting fit parameters\n",
    "# fit_cov: the covariance matrix between all the parameters\n",
    "#          (used to extract fitting parameter uncertanties)\n",
    "# maxfev=10**5: maximum number of fitting procedure iterations before giving up\n",
    "# absolute_sigma=True: uncertainties are treated as absolute (not relative)\n",
    "fit_params, fit_cov = curve_fit(\n",
    "    fit_function, x, y, sigma=y_sigma, \n",
    "    p0=guesses,absolute_sigma=True, maxfev=10**5)\n",
    "\n",
    "# Define the function that calculates chi-squared\n",
    "def chi_square(fit_parameters, x, y, sigma):\n",
    "    dof = len(x) - len(fit_params)\n",
    "    return np.sum((y - fit_function(x, *fit_parameters)) ** 2 / sigma**2)/dof\n",
    "\n",
    "# Calculate and print reduced chi-squared\n",
    "chi2 = chi_square(fit_params, x, y, y_sigma)\n",
    "print(\"Chi-squared = \", chi2)\n",
    "\n",
    "# Calculate the uncertainties in the fit parameters\n",
    "fit_params_error = np.sqrt(np.diag(fit_cov))\n",
    "\n",
    "# Print the fit parameters with uncertianties\n",
    "print(\"\\nFit parameters:\")\n",
    "for i in range(len(fit_params)):\n",
    "    print(f\"   {param_names[i]} = {fit_params[i]:.3e} ± {fit_params_error[i]:.3e}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# (Optional) Print the covariance between all variables\n",
    "if show_covariance_matrix:\n",
    "    print(\"Covariance between fit parameters:\")\n",
    "    for i, fit_covariance in enumerate(fit_cov):\n",
    "        for j in range(i+1,len(fit_covariance)):\n",
    "            print(f\"   {param_names[i]} and {param_names[j]}: {fit_cov[i,j]:.3e}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# residual is the difference between the data and model\n",
    "x_fitfunc = np.linspace(min(x), max(x), len(x))\n",
    "y_fitfunc = fit_function(x_fitfunc, *fit_params)\n",
    "y_fit = fit_function(x, *fit_params)\n",
    "residual = y-y_fit\n",
    "\n",
    "###############################################################################\n",
    "# PRODUCE A MULTIPANEL PLOT, WITH SCATTER PLOT, RESIDUALS AND RESIDUALS HISTOGRAM\n",
    "###############################################################################\n",
    "\n",
    "# The size of the canvas\n",
    "fig = plt.figure(figsize=(7,15))\n",
    "\n",
    "# The scatter plot\n",
    "ax1 = fig.add_subplot(311)\n",
    "ax1.errorbar(x,y,yerr=y_sigma,marker='.',linestyle='',label=\"Measured data\")\n",
    "ax1.plot(x_fitfunc, y_fitfunc, marker=\"\", linestyle=\"-\", linewidth=2,color=\"r\", label=\"Fit\")\n",
    "ax1.set_xlabel(f\"{x_name} [{x_units}]\")\n",
    "ax1.set_ylabel(f\"{y_name} [{y_units}]\")\n",
    "ax1.set_title('Best Fit of Function to Data')\n",
    "\n",
    "# (Optional) set the x and y boundaries of your plot\n",
    "if set_xy_boundaries:\n",
    "    plt.xlim(lower_x,upper_x)\n",
    "    plt.ylim(lower_y,upper_y)\n",
    "# Show the legend. loc='best' places it where the date are least obstructed\n",
    "ax1.legend(loc='best',numpoints=1)\n",
    "\n",
    "# The residuals plot\n",
    "ax2 = fig.add_subplot(312)\n",
    "ax2.errorbar(x, residual, yerr=y_sigma,marker='.', linestyle='', label=\"Residual (y-y_fit)\")\n",
    "ax2.hlines(0,np.min(x),np.max(x),lw=2,alpha=0.8)\n",
    "ax2.set_xlabel(f\"{x_name} [{x_units}]\")\n",
    "ax2.set_ylabel(f\"y-y_fit [{y_units}]\")\n",
    "ax2.set_title('Residuals for the Best Fit')\n",
    "ax2.legend(loc='best',numpoints=1)\n",
    "\n",
    "# Histogram of the residuals -> commented out 2025 as extranous; plot of residuals more informative\n",
    "#ax3 = fig.add_subplot(313)\n",
    "#hist,bins = np.histogram(residual,bins=30)\n",
    "#ax3.bar(bins[:-1],hist,width=bins[1]-bins[0])\n",
    "#ax3.set_ylim(0,1.2*np.max(hist))\n",
    "#ax3.set_xlabel(f\"y-y_fit [{y_units}]\")\n",
    "#ax3.set_ylabel('Number of occurences')\n",
    "#ax3.set_title('Histogram of the Residuals')\n",
    "\n",
    "# Save a copy of the figure as a png \n",
    "plt.savefig('FittingResults.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7e7172-dfba-4bd5-ace2-eb3ef8814b20",
   "metadata": {},
   "source": [
    "Comment on the residuals and quality of the fit. What does this say about the data you aquired? About the model you are using to describe the data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fbd3d2-125d-41ee-98d5-d5f9667e20eb",
   "metadata": {},
   "source": [
    "## Data Set 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8523cabe-b45e-449f-8651-18e59d79279f",
   "metadata": {},
   "source": [
    "Now that we've gone through the process a couple of times, try copying the merged cells from Data set 2 above to analyze your additional data sets. You need to:\n",
    "* Acquire and save the data, and record any observations you have\n",
    "* Load and examine the data\n",
    "* Pack the data\n",
    "* Fit the expected function to the data\n",
    "* Assess the results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60493996-ddff-4a39-a614-736c6aaedb3f",
   "metadata": {},
   "source": [
    "## Data Set 4: the best one!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1652e5fd-b08f-4305-ab73-e5111057d34e",
   "metadata": {},
   "source": [
    "Hopefully having encountered a few (intentional) issues, you have been able to acquire one really clean data set. Analyze this final, best example here, and comment on whether it follows your expectations, and if not what you might still need to do to optimize either your data collection or the model, or both."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496154aa-4f57-4928-85a4-f952e025232b",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aea60a2-4f74-4507-a261-8c370df32789",
   "metadata": {},
   "source": [
    "Now that you've taken data under different conditions, fit a model to the data, and compared both the direct outputs and the quality of the fits to a reasonably expected model, write a few notes to yourself for things to look for and consider when setting up your circuit, signals and data acquisition with the oscilloscope."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
