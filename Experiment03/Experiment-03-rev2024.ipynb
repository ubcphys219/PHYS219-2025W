{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a038bf36-ca64-472c-b797-374ef246c9d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Experiment 03  -  LRC Transients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa9513ab-1d5e-4c54-ae71-58105423ef71",
   "metadata": {},
   "source": [
    "Date:\n",
    "\n",
    "Name:\n",
    "\n",
    "Partner's name:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a826b-8f18-483a-95b1-ab91cd7ab639",
   "metadata": {},
   "source": [
    "## Place a heading here to indicate what you are working on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "957c2a07-b52e-4bb4-909a-bbbd6a7f6376",
   "metadata": {},
   "source": [
    "Enter notes here as you work through the experiment. Begin with a brief statement about what you will be working on, and why. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e0363f-9316-4c87-95d2-746cbc005d4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## You might need another heading here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e2338-9d8a-454f-b677-b1499eb58ce7",
   "metadata": {},
   "source": [
    "As you progress through the lab, keep adding notes, and include headings to help keep things organized. We will provide much less structure in this notebook, so it is up to you to take notes as you go along. We will be checking your work during the lab."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c435595f-277e-4cb4-a0fc-dfa981a81b99",
   "metadata": {},
   "source": [
    "## Measurements of Inductance, Resistance, and Capacitance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14575c3b-cc4e-4643-b178-22a36209d856",
   "metadata": {},
   "source": [
    "Record the measured values of L, R, and C for the components that you are using in your circuit. To estimate the uncertainties in these values, you will need to consult the manual for your DMM. I recommend storing these values as variables, but also make sure they are visible (i.e. you can use a `print()` statement to show what you have recorded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0237d005-742a-4be4-aaab-423e208c0bd4",
   "metadata": {},
   "source": [
    "During the lab, you will be changing the capacitance of the variable capacitor, so you may want to make an array of these values and be able to add values to it (\"append\"). You may also want to store the parameters output by the fitting function for each value of the capacitance. See the optional pre-lab section for examples of how to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a01e15-8988-460d-bced-4b12dc3f50f2",
   "metadata": {},
   "source": [
    "## The Rest of the Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c354a058-285d-449a-89e6-8442af69038a",
   "metadata": {
    "tags": []
   },
   "source": [
    "The rest of this experiment goes rather similarly to Experiment 02 on the RC transient; the main difference is that the transient is a little more interesting. You will be capturing transients on the oscilloscope for several different values of the capacitance. The aim is that you will have enough data to study the dependence of resonant frequency on capacitance. So, below you will be recording your measured values of capacitance, and repeating the analysis of your transient data for each of your capacitance values.\n",
    "\n",
    "For the remainder of the lab notes, remember to:\n",
    "\n",
    "- keep writing down what you are doing, at the time you are doing it.\n",
    "- don't forget to include uncertainties and units for all measured quantities\n",
    "- don't forget to record the names of data files, so that it is easy to keep track of things\n",
    "- make sure to show and store all necessary values\n",
    "\n",
    "You will reuse the two pieces of code from last week, the code for packing and trimming the data, and the code for fitting. We include these again here for your convenience, with the places for editing indicated by \"Modify  \" notes in red.\n",
    "\n",
    "As a reminder, you need to alter the following lines when packing the data:\n",
    "- the name for your uploaded raw data file\n",
    "- the zoomed in flat range you use to examine the noise and measure the standard deviation\n",
    "- the number of points you want to average when packing the data (you may need to decide how to trade off more averaging against having a sufficient density of points more in this experiment than the last one)\n",
    "- a new index range that you can use to trim unwanted data at the start or end of the time range, toggling the `trim` flag from `0` to `1`\n",
    "- the filename you will use to save your packed and trimmed data \n",
    "\n",
    "You need to alter the following lines when fitting the data:\n",
    "- the name of your packed data file - modify the line containing `fname = ...`\n",
    "- your fitting function - modify the line `def fit_function(....)` and \"return ...\"\n",
    "- your initial guesses for the parameters\n",
    "- the parameter names in \"param_names = ...\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc3d10e-d823-4b30-97df-8181c44e5213",
   "metadata": {},
   "source": [
    "## Dataset 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c606af-403f-4b54-8b0b-58d0abb9cac2",
   "metadata": {},
   "source": [
    "Load your first data set, determine uncertainties (note that if you only have bit-noise between two values on a few points, you may want to select `digital` which takes the $(min-max)/\\sqrt{3}$ instead of the `default` which uses the standard deviation of the selected data), determine how many points to average (pack), and trim the data to the relevant region of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3e358f-51d4-466e-9fbb-e62e9936d885",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the  necessary libraries and rename them\n",
    "import numpy as np\n",
    "import array\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "###############################################################################\n",
    "# LIST OF ALL INPUTS\n",
    "###############################################################################\n",
    "\n",
    "fname = 'RCdecayVC3.csv' # file name containing your raw data\n",
    "\n",
    "title='My Packed MicSig Data' # give your graph a title\n",
    "output_name = 'RCdecayVC3_packed.csv' # provide an output filename for the packed data\n",
    "\n",
    "# choose the data range you want to examine\n",
    "indexraw_min = 0\n",
    "indexraw_max = 2000\n",
    "\n",
    "# set y-scale to correspond to this range\n",
    "yregion_min=5.2\n",
    "yregion_max=4.8\n",
    "\n",
    "# select an uncertainty type\n",
    "# \"default\" uses the standard deviation of the selected flat region\n",
    "# if standard deviation is unreasonably small and/or shows only digitization noise with single bit flips,\n",
    "# set uncertainty type to \"digital\" to take the standard deviation of a boxcar defined by the max/min values\n",
    "# or, set uncertainty type to \"manual\" and set a value for manualsigma\n",
    "uncertainty = \"default\"\n",
    "manualsigma = 0\n",
    "\n",
    "npac=100 # define packing factor  npac\n",
    "\n",
    "# trim data set range before output to .csv file\n",
    "trim = 0 # default is 0 to save full dataset, set trim to 1 to trim the output data then give the range\n",
    "trim_min=50 # start of trimmed data by packed index\n",
    "trim_max=800 # end of trimmed data by packed index\n",
    "\n",
    "###############################################################################\n",
    "# READ IN DATA\n",
    "###############################################################################\n",
    "\n",
    "# read in data - the file is assumed to be in csv format (comma separated variables). \n",
    "#Files need to be specified with a full path OR they have to be saved in the same folder \n",
    "#as the script\n",
    "data = np.loadtxt(fname, delimiter=',', comments='#',usecols=(3,4),skiprows=1)\n",
    "#data = np.loadtxt(fname, delimiter=',',comments='#' )\n",
    "# access the data columns and assign variables xraw and yraw\n",
    "#generate  an array  xraw  which is the first  column  of  data.  Note the first column is \n",
    "#indexed as  zero.\n",
    "xraw = data[:,0]\n",
    "#generate  an array  yraw  which is the second  column  of  data  (index  1)\n",
    "yraw = data[:,1]\n",
    "#generate array containing index\n",
    "indexraw=np.arange(len(xraw))\n",
    "\n",
    "# plot data versus time and data versus index\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.scatter(xraw, yraw,marker='.')\n",
    "ax1.set_xlabel('Time (sec)')\n",
    "ax1.set_ylabel('Voltage (V)')\n",
    "ax1.set_title('My Raw MicSig Data')\n",
    "ax2 = fig.add_subplot(122)\n",
    "ax2.scatter(indexraw,yraw,marker='.')\n",
    "ax2.set_xlabel('Index')\n",
    "ax2.set_ylabel('Voltage (V)')\n",
    "plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# PLOT RESTRICTED INDEX RANGE OF FLAT DATA, CALCULATE UNCERTAINTY\n",
    "# plots a restricted index range where the data is flat\n",
    "# and calculates the standard deviation to assess the noise\n",
    "###############################################################################\n",
    "\n",
    "# change axis limits\n",
    "plt.xlim(indexraw_min,indexraw_max)\n",
    "plt.ylim(yregion_min,yregion_max)\n",
    "\n",
    "# plot the data versus index\n",
    "plt.scatter(indexraw,yraw,marker='.')\n",
    "\n",
    "# This next command displays the index plot. \n",
    "plt.show()\n",
    "\n",
    "#calculate and display the mean and standard deviation of the data that you have zoomed in on.\n",
    "y_ave = np.mean(yraw[indexraw_min:indexraw_max])\n",
    "y_std = np.std(yraw[indexraw_min:indexraw_max])\n",
    "print('mean = ',y_ave)\n",
    "print('standard deviation = ', y_std)\n",
    "\n",
    "# display a histogram of the data\n",
    "hist,bins = np.histogram(yraw[indexraw_min:indexraw_max],bins=20)\n",
    "plt.bar(bins[:-1],hist,width=bins[1]-bins[0])\n",
    "plt.ylim(0,1.2*np.max(hist))\n",
    "plt.xlabel('y_raw (Volts)')\n",
    "plt.ylabel('Number of occurences')\n",
    "plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# PACK AND TRIM DATA\n",
    "###############################################################################\n",
    "\n",
    "#define a function  to pack the data\n",
    "def pack(A,p):\n",
    "  # A is an array, and p is the packing factor\n",
    "  B = np.zeros(len(A)//p)\n",
    "  i = 1\n",
    "  while i-1<len(B):\n",
    "    B[i-1] = np.mean(A[p*(i-1):p*i])\n",
    "    i += 1\n",
    "  return B\n",
    "# pack the data\n",
    "x=pack(xraw,npac)\n",
    "y=pack(yraw,npac)\n",
    "\n",
    "#create a vector that also has the integer index (index = 0,1,2 ... length-1)\n",
    "length=len(x)\n",
    "#print(length)\n",
    "index = np.arange(length)\n",
    "\n",
    "#create a vector that contains fixed uncertainty for x values (in this case set to zero\n",
    "sigmax = [0]*length\n",
    "#print(sigmax)\n",
    "\n",
    "#Create a vector that contains uncertainty of averaged y values. \n",
    "#sigmayraw is your estimate of the uncertainty in individual raw data points\n",
    "\n",
    "#Here it is taking that value from your previous statistics code \n",
    "#If the data sampled shows only a small amount of digitization noise, and the standard deviation is unreasonably small, \n",
    "#select \"digital\" above to take the stdev of a boxcar of the width of the digitization\n",
    "#If you think the standard deviation of your data is an underestimate of the uncertainty,\n",
    "#you can also enter a value by hand - just change the line that defines simayraw\n",
    "\n",
    "if uncertainty == \"digital\":\n",
    "    sigmayraw = 0.5 * (np.max(yraw[indexraw_min:indexraw_max])-np.min(yraw[indexraw_min:indexraw_max]))/np.sqrt(3)\n",
    "    print(\"digital uncertainty used:\",sigmayraw)\n",
    "elif uncertainty == \"manual\":\n",
    "    sigmayraw = manualsigma\n",
    "    print(\"manually specified uncertainty used:\",sigmayraw)\n",
    "else:\n",
    "    sigmayraw = y_std\n",
    "    \n",
    "\n",
    "#sigmaymean is the uncertainty of y after averaging npac points together\n",
    "#sigmay is an array of uncertainties, all of the same value as sigmaymean\n",
    "sigmaymean = sigmayraw/np.sqrt(npac)\n",
    "sigmay = [sigmaymean]*length\n",
    "\n",
    "print('packing is done by averaging', npac, 'data points')\n",
    "\n",
    "if trim == 1:\n",
    "    index_min=trim_min\n",
    "    index_max=trim_max\n",
    "    print('packed data has been trimmed from ', index_min, 'to ', index_max)\n",
    "else:\n",
    "    index_min=0\n",
    "    index_max=length\n",
    "    print('packed data contains full data set')\n",
    "\n",
    "# plot the trimmed data versus index\n",
    "plt.errorbar(index,y,yerr=sigmay,marker='.',linestyle='')\n",
    "## marker='o' : use markers to indicate each data point (x_1,y_1),(x_2,y_2)\n",
    "## linestyle= '' : no line is drawn to connect the data points\n",
    "## linestyle= '-' : a line is drawn to connect the data points\n",
    "\n",
    "# change axis limits\n",
    "plt.xlim(index_min,index_max)\n",
    "\n",
    "# add axis labels\n",
    "plt.title('Packed and Trimmed Data For Storage')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Voltage (V)')\n",
    "plt.show()\n",
    "\n",
    "# Create Array and output as CSV file in four-column format with two-row headers\n",
    "\n",
    "header = [np.array(['time','u[time]','Voltage','u[Voltage]']), \n",
    "np.array(['(sec)','(sec)','(V)','(V)'])]\n",
    "d1 = [x[index_min:index_max] , sigmax[index_min:index_max] , y[index_min:index_max] , sigmay[index_min:index_max]]\n",
    "d1_a = np.array(d1)\n",
    "df = pd.DataFrame(np.transpose(d1_a), columns=header )   \n",
    "    \n",
    "# print(df)\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "# SAVE DATA TO FILE\n",
    "###############################################################################\n",
    "\n",
    "csv_data = df.to_csv(output_name, index = False)\n",
    "print('Packed Data Stored in ', output_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710eb4e3-731e-48db-a32f-7c6b0eadffaa",
   "metadata": {},
   "source": [
    "Next, fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bc66aa-a679-45c5-8143-d26c083066bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load python packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "###############################################################################\n",
    "# DEFINED FITTING FUNCTIONS\n",
    "###############################################################################\n",
    "\n",
    "def sine_func(x, amplitude, freq, phase):\n",
    "    return amplitude * np.sin(2.0 * np.pi * freq * x + phase)\n",
    "\n",
    "def offset_sine_func(x, amplitude, freq, phase, offset):\n",
    "    return (amplitude * np.sin(2.0 * np.pi * freq * x + phase)) + offset\n",
    "\n",
    "def exponential_func(x, amplitude, tau, voffset):\n",
    "    return amplitude * np.exp(x/(-1.0*tau)) + voffset\n",
    "\n",
    "def ringdown_function(x, amplitude, tau, resonantf, phase):\n",
    "    return amplitude * np.exp(-x/tau) * np.cos(2.0*np.pi * resonantf * x + phase)\n",
    "\n",
    "def linear_func(x, slope, intercept):\n",
    "    return slope * x + intercept\n",
    "\n",
    "###############################################################################\n",
    "# LIST OF ALL INPUTS\n",
    "###############################################################################\n",
    "\n",
    "# Name of the data file\n",
    "fname = \"sintest2_pack.csv\"\n",
    "\n",
    "# Names and units of data columns from fname\n",
    "x_name = \"Time\"\n",
    "x_units = \"s\"\n",
    "y_name = \"Voltage\"\n",
    "y_units = \"V\"\n",
    "\n",
    "# Modify to change the fitting function, parameter names and to set initial parameter guesses\n",
    "fit_function = sine_func\n",
    "param_names = (\"amplitude\", \"frequency\", \"phase\")\n",
    "guesses = (1.0, 900, 0.1)\n",
    "\n",
    "# Flags for optional features\n",
    "show_covariance_matrix = False\n",
    "set_xy_boundaries = False\n",
    "lower_x = -0.01 # these values ignored if set_xy_boundaries = False\n",
    "upper_x = 0.01\n",
    "lower_y = -1\n",
    "upper_y = 1\n",
    "\n",
    "###############################################################################\n",
    "# LOAD DATA\n",
    "###############################################################################\n",
    "\n",
    "# load the file fname and skip the first 'skiprows' rows\n",
    "data = np.loadtxt(fname, delimiter=\",\", comments=\"#\", usecols=(0, 1, 2, 3), skiprows=2)\n",
    "\n",
    "# Assign the data file columns to variables for later use\n",
    "x = data[:, 0]\n",
    "y = data[:, 2]\n",
    "y_sigma = data[:, 3]\n",
    "\n",
    "###############################################################################\n",
    "# INITIAL PLOT OF THE DATA\n",
    "###############################################################################\n",
    "\n",
    "# Define 500 points spanning the range of the x-data; for plotting smooth curves\n",
    "xtheory = np.linspace(min(x), max(x), 500)\n",
    "\n",
    "# Compare the guessed curve to the data for visual reference\n",
    "y_guess = fit_function(xtheory, *guesses)\n",
    "plt.errorbar(x, y, yerr=y_sigma, marker=\".\", linestyle=\"\", label=\"Measured data\")\n",
    "plt.plot(\n",
    "    xtheory,\n",
    "    y_guess,\n",
    "    marker=\"\",\n",
    "    linestyle=\"-\",\n",
    "    linewidth=1,\n",
    "    color=\"g\",\n",
    "    label=\"Initial parameter guesses\",\n",
    ")\n",
    "plt.xlabel(f\"{x_name} [{x_units}]\")\n",
    "plt.ylabel(f\"{y_name} [{y_units}]\")\n",
    "plt.title(r\"Comparison between the data and the intial parameter guesses\")\n",
    "plt.legend(loc=\"best\", numpoints=1)\n",
    "plt.show()\n",
    "\n",
    "# calculate the value of the model at each of the x-values of the data set\n",
    "y_fit = fit_function(x, *guesses)\n",
    "\n",
    "# Residuals are the difference between the data and theory\n",
    "residual = y - y_fit\n",
    "\n",
    "# Plot the residuals\n",
    "plt.errorbar(x, residual, yerr=y_sigma, marker=\".\", linestyle=\"\", label=\"residuals\")\n",
    "plt.xlabel(f\"{x_name} [{x_units}]\")\n",
    "plt.ylabel(f\"Residual y-y_fit [{y_units}]\")\n",
    "plt.title(\"Residuals using initial parameter guesses\")\n",
    "plt.show()\n",
    "\n",
    "###############################################################################\n",
    "# PERFORM THE FIT AND PRINT RESULTS\n",
    "###############################################################################\n",
    "\n",
    "# Use curve_fit to perform the fit\n",
    "# fit_function: defined above to choose a specific fitting function \n",
    "# fit_params: holds the resulting fit parameters\n",
    "# fit_cov: the covariance matrix between all the parameters\n",
    "#          (used to extract fitting parameter uncertanties)\n",
    "# maxfev=10**5: maximum number of fitting procedure iterations before giving up\n",
    "# absolute_sigma=True: uncertainties are treated as absolute (not relative)\n",
    "fit_params, fit_cov = curve_fit(\n",
    "    fit_function, x, y, sigma=y_sigma, \n",
    "    p0=guesses,absolute_sigma=True, maxfev=10**5)\n",
    "\n",
    "# Define the function that calculates chi-squared\n",
    "def chi_square(fit_parameters, x, y, sigma):\n",
    "    dof = len(x) - len(fit_params)\n",
    "    return np.sum((y - fit_function(x, *fit_parameters)) ** 2 / sigma**2)/dof\n",
    "\n",
    "# Calculate and print reduced chi-squared\n",
    "chi2 = chi_square(fit_params, x, y, y_sigma)\n",
    "print(\"Chi-squared = \", chi2)\n",
    "\n",
    "# Calculate the uncertainties in the fit parameters\n",
    "fit_params_error = np.sqrt(np.diag(fit_cov))\n",
    "\n",
    "# Print the fit parameters with uncertianties\n",
    "print(\"\\nFit parameters:\")\n",
    "for i in range(len(fit_params)):\n",
    "    print(f\"   {param_names[i]} = {fit_params[i]:.3e} ± {fit_params_error[i]:.3e}\")\n",
    "print(\"\\n\")\n",
    "\n",
    "# (Optional) Print the covariance between all variables\n",
    "if show_covariance_matrix:\n",
    "    print(\"Covariance between fit parameters:\")\n",
    "    for i, fit_covariance in enumerate(fit_cov):\n",
    "        for j in range(i+1,len(fit_covariance)):\n",
    "            print(f\"   {param_names[i]} and {param_names[j]}: {fit_cov[i,j]:.3e}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "# residual is the difference between the data and model\n",
    "x_fitfunc = np.linspace(min(x), max(x), len(x))\n",
    "y_fitfunc = fit_function(x_fitfunc, *fit_params)\n",
    "y_fit = fit_function(x, *fit_params)\n",
    "residual = y-y_fit\n",
    "\n",
    "###############################################################################\n",
    "# PRODUCE A MULTIPANEL PLOT, WITH SCATTER PLOT, RESIDUALS AND RESIDUALS HISTOGRAM\n",
    "###############################################################################\n",
    "\n",
    "# The size of the canvas\n",
    "fig = plt.figure(figsize=(7,10))\n",
    "\n",
    "# The scatter plot\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.errorbar(x,y,yerr=y_sigma,marker='.',linestyle='',label=\"Measured data\")\n",
    "ax1.plot(x_fitfunc, y_fitfunc, marker=\"\", linestyle=\"-\", linewidth=2,color=\"r\", label=\"Fit\")\n",
    "ax1.set_xlabel(f\"{x_name} [{x_units}]\")\n",
    "ax1.set_ylabel(f\"{y_name} [{y_units}]\")\n",
    "ax1.set_title('Best Fit of Function to Data')\n",
    "\n",
    "# (Optional) set the x and y boundaries of your plot\n",
    "if set_xy_boundaries:\n",
    "    plt.xlim(lower_x,upper_x)\n",
    "    plt.ylim(lower_y,upper_y)\n",
    "# Show the legend. loc='best' places it where the date are least obstructed\n",
    "ax1.legend(loc='best',numpoints=1)\n",
    "\n",
    "# The residuals plot\n",
    "ax2 = fig.add_subplot(212)\n",
    "ax2.errorbar(x, residual, yerr=y_sigma,marker='.', linestyle='', label=\"Residual (y-y_fit)\")\n",
    "ax2.hlines(0,np.min(x),np.max(x),lw=2,alpha=0.8)\n",
    "ax2.set_xlabel(f\"{x_name} [{x_units}]\")\n",
    "ax2.set_ylabel(f\"y-y_fit [{y_units}]\")\n",
    "ax2.set_title('Residuals for the Best Fit')\n",
    "ax2.legend(loc='best',numpoints=1)\n",
    "\n",
    "# Histogram of the residuals -- commented out 2025; deemed extraneous, see distribution of residuals in plot above\n",
    "# ax3 = fig.add_subplot(313)\n",
    "# hist,bins = np.histogram(residual,bins=30)\n",
    "# ax3.bar(bins[:-1],hist,width=bins[1]-bins[0])\n",
    "# ax3.set_ylim(0,1.2*np.max(hist))\n",
    "# ax3.set_xlabel(f\"y-y_fit [{y_units}]\")\n",
    "# ax3.set_ylabel('Number of occurences')\n",
    "# ax3.set_title('Histogram of the Residuals')\n",
    "\n",
    "# Save a copy of the figure as a png \n",
    "plt.savefig('FittingResults.png')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d488e33-2b6e-4be2-b071-e490877b8e2f",
   "metadata": {},
   "source": [
    "Consider creating arrays for each of the fit parameters: `amplitude`, `tau`, `resonantfreq`, `phase`, `voffset` that can be apppended with each additional fit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d2e4a-c621-4fa3-9719-d73a8456d75d",
   "metadata": {},
   "source": [
    "## Dataset 2 (and so-on)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e52b83b-54cc-4223-adc1-558406421d74",
   "metadata": {},
   "source": [
    "Repeat the this packing and fitting process with each data set until you have enough results to generate a plot of the fit parameters vs. capacitance. Remember to keep notes for each dataset, and make comments on the fit. If you are not satisfied with the fit quality, you may need to go back to the \"pack and trim\" step to prepare your data (e.g. if uncertainty is under/over-estimated or the residuals show you may have captured part of the data would not be described by the model). If you do this, make sure to comment on what you saw and why you adjusted the parameters you did.\n",
    "If you don't include the full code blocks here, make sure to store the results of the packing and fitting in files with different names, and remember to record the names here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbbdb2e-514e-4378-8a3a-4a67520a7d96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
